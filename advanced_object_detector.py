"""
üö® ADVANCED OBJECT DETECTION SYSTEM V1.0
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏•‡∏≠‡∏° (‡∏Ñ‡∏ô ‡∏™‡∏±‡∏ï‡∏ß‡πå ‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞ ‡∏Ø‡∏•‡∏Ø)
‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏Å‡πÇ‡∏î‡∏¢‡∏™‡∏¥‡πâ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á

Features:
‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö 80+ ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
‚úÖ ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö Real-time
‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô
‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠
‚úÖ ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
"""

import cv2
import cv2
import numpy as np
from ultralytics import YOLO
import time
from datetime import datetime
import sqlite3
import json
import os
from typing import Dict, List, Tuple, Optional

class AdvancedObjectDetector:
    """üéØ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏•‡∏≠‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    
    def __init__(self):
        self.model = None
        self.detected_objects = []
        self.alert_history = []
        self.db_path = "object_detection_alerts.db"
        self.confidence_threshold = 0.25  # ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
        self.last_detection_time = {}
        self.cooldown_seconds = 1.5  # ‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤ cooldown ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
        
        # üö® ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏•‡∏≠‡∏°)
        self.critical_objects = {
            # ‡∏Ñ‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ - ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
            'person': {'name': '‡∏Ñ‡∏ô', 'priority': 'CRITICAL', 'color': (0, 0, 255)},
            'cat': {'name': '‡πÅ‡∏°‡∏ß', 'priority': 'HIGH', 'color': (0, 165, 255)},
            'dog': {'name': '‡∏™‡∏∏‡∏ô‡∏±‡∏Ç', 'priority': 'HIGH', 'color': (0, 165, 255)},
            'bird': {'name': '‡∏ô‡∏Å‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏ç‡πà (‡πÄ‡∏´‡∏¢‡∏µ‡πà‡∏¢/‡∏û‡∏¥‡∏£‡∏≤‡∏ö)', 'priority': 'HIGH', 'color': (255, 100, 0)},
            'mouse': {'name': '‡∏´‡∏ô‡∏π/‡∏ï‡∏∏‡∏Å‡πÅ‡∏Å', 'priority': 'HIGH', 'color': (255, 165, 0)},
            
            # ‡∏á‡∏π ‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÄ‡∏•‡∏∑‡πâ‡∏≠‡∏¢‡∏Ñ‡∏•‡∏≤‡∏ô (‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö)
            'snake': {'name': '‡∏á‡∏π', 'priority': 'CRITICAL', 'color': (128, 0, 128)},
            
            # ‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏õ‡πà‡∏≤‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢
            'bear': {'name': '‡∏´‡∏°‡∏µ', 'priority': 'CRITICAL', 'color': (0, 0, 255)},
            'elephant': {'name': '‡∏ä‡πâ‡∏≤‡∏á', 'priority': 'CRITICAL', 'color': (0, 0, 255)},
            'horse': {'name': '‡∏°‡πâ‡∏≤', 'priority': 'MEDIUM', 'color': (255, 165, 0)},
            'cow': {'name': '‡∏ß‡∏±‡∏ß/‡∏Ñ‡∏ß‡∏≤‡∏¢', 'priority': 'MEDIUM', 'color': (255, 165, 0)},
            'sheep': {'name': '‡πÅ‡∏Å‡∏∞', 'priority': 'MEDIUM', 'color': (255, 165, 0)},
            
            # ‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏á‡∏™‡∏±‡∏¢
            'car': {'name': '‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå', 'priority': 'MEDIUM', 'color': (255, 165, 0)},
            'motorcycle': {'name': '‡∏£‡∏ñ‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏ã‡∏Ñ‡πå', 'priority': 'MEDIUM', 'color': (255, 165, 0)},
            'bicycle': {'name': '‡∏à‡∏±‡∏Å‡∏£‡∏¢‡∏≤‡∏ô', 'priority': 'LOW', 'color': (255, 255, 0)},
            'truck': {'name': '‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å', 'priority': 'MEDIUM', 'color': (255, 165, 0)},
            
            # ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏á‡∏™‡∏±‡∏¢
            'backpack': {'name': '‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡πÄ‡∏õ‡πâ', 'priority': 'LOW', 'color': (255, 255, 0)},
            'umbrella': {'name': '‡∏£‡πà‡∏°', 'priority': 'LOW', 'color': (255, 255, 0)},
            'handbag': {'name': '‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡∏ñ‡∏∑‡∏≠', 'priority': 'LOW', 'color': (255, 255, 0)},
        }
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        self.frame_skip_counter = 0
        self.detection_frequency = 5  # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏∏‡∏Å 5 ‡πÄ‡∏ü‡∏£‡∏° (‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ CPU)
        self.last_detection_results = []  # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠ smooth detection
        
        self._init_database()
        self._load_model()
    
    def _load_model(self):
        """‡πÇ‡∏´‡∏•‡∏î YOLO model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏"""
        try:
            print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Advanced Object Detection Model...")
            # ‡πÉ‡∏ä‡πâ YOLOv8 model ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á
            model_path = "yolov8n.pt"  # ‡πÉ‡∏ä‡πâ model ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÅ‡∏ï‡πà config ‡∏ï‡πà‡∏≤‡∏á
            
            if os.path.exists(model_path):
                self.model = YOLO(model_path)
                print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î Object Detection Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
            else:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Model file")
                return False
                
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model: {e}")
            return False
        return True
    
    def _init_database(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS object_alerts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    object_type TEXT NOT NULL,
                    object_name TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    priority TEXT NOT NULL,
                    bbox_x INTEGER NOT NULL,
                    bbox_y INTEGER NOT NULL,
                    bbox_width INTEGER NOT NULL,
                    bbox_height INTEGER NOT NULL,
                    image_path TEXT,
                    status TEXT DEFAULT 'NEW'
                )
            ''')
            
            conn.commit()
            conn.close()
            print("‚úÖ Database Object Detection ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î Database: {e}")
    
    def detect_objects(self, frame: np.ndarray, camera_props=None, frame_quality=None) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏° ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏û‡∏¥‡πÄ‡∏®‡∏©"""
        # ‡πÉ‡∏ä‡πâ frame skipping ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        self.frame_skip_counter += 1
        if self.frame_skip_counter % self.detection_frequency != 0:
            # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏ú‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
            return self.last_detection_results[:3] if self.last_detection_results else []
        
        detections = []
        
        # 1. ‡πÉ‡∏ä‡πâ YOLO detection ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
        if self.model is not None:
            try:
                yolo_detections = self._detect_with_yolo(frame)
                detections.extend(yolo_detections)
            except Exception as e:
                print(f"‚ö†Ô∏è YOLO detection error: {e}")
        
        # 2. ‡πÉ‡∏ä‡πâ motion detection ‡πÄ‡∏õ‡πá‡∏ô backup (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ YOLO detections ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)
        critical_found = any(d.get('priority') == 'CRITICAL' for d in detections)
        if not critical_found:
            motion_detections = self._detect_with_motion(frame)
            detections.extend(motion_detections)
        
        # 3. ‡∏•‡∏ö detection ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
        detections = self._remove_duplicate_detections(detections)
        
        # 4. ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô detections ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        detections = detections[:5]  # ‡∏•‡∏î‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 5 detections
        
        # 5. ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏ß‡πâ
        self.last_detection_results = detections.copy()
        
        return detections
    
    def _detect_with_yolo(self, frame: np.ndarray) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ YOLO model"""
        if self.model is None:
            return []
        
        try:
            # ‡∏£‡∏±‡∏ô YOLO detection
            results = self.model(frame, conf=self.confidence_threshold, verbose=False)
            detections = []
            current_time = time.time()
            
            for r in results:
                boxes = r.boxes
                if boxes is not None and hasattr(boxes, 'xyxy') and hasattr(boxes.xyxy, 'shape') and boxes.xyxy.shape[0] > 0:
                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy arrays ‡∏Å‡πà‡∏≠‡∏ô
                    xyxy = boxes.xyxy.cpu().numpy()
                    conf = boxes.conf.cpu().numpy()
                    cls = boxes.cls.cpu().numpy()
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    if hasattr(xyxy, 'shape') and xyxy.shape[0] > 0:
                        for i in range(xyxy.shape[0]):
                            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• detection
                            x1, y1, x2, y2 = xyxy[i]
                            confidence = float(conf[i])
                            class_id = int(cls[i])
                            
                            # ‡πÅ‡∏õ‡∏•‡∏á class_id ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
                            object_type = self.model.names[class_id]
                            
                            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡πÑ‡∏´‡∏°
                            if object_type in self.critical_objects:
                                object_info = self.critical_objects[object_type]
                                
                                # ‡πÄ‡∏ä‡πá‡∏Ñ cooldown ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ã‡πâ‡∏≥
                                cooldown_key = f"{object_type}_{int(x1)}_{int(y1)}"
                                if (cooldown_key not in self.last_detection_time or 
                                    current_time - self.last_detection_time[cooldown_key] > self.cooldown_seconds):
                                    
                                    detection = {
                                        'object_type': object_type,
                                        'object_name': object_info['name'],
                                        'confidence': confidence,
                                        'priority': object_info['priority'],
                                        'color': object_info['color'],
                                        'bbox': (int(x1), int(y1), int(x2-x1), int(y2-y1)),
                                        'center': (int((x1+x2)/2), int((y1+y2)/2)),
                                        'timestamp': datetime.now().isoformat(),
                                        'source': 'yolo'
                                    }
                                    
                                    detections.append(detection)
                                    self.last_detection_time[cooldown_key] = current_time
                                    
                                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á database
                                    self._save_alert_to_db(detection, frame)
                                    
                                    # ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô Chatbot
                                    self._notify_chatbot(detection)
            
            return detections
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö YOLO: {e}")
            return []
    
    def _detect_with_motion(self, frame: np.ndarray) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß (fallback method) - ‡πÄ‡∏ô‡πâ‡∏ô‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô"""
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á background model ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            if not hasattr(self, '_background_model'):
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                self._background_model = cv2.createBackgroundSubtractorMOG2(
                    detectShadows=True,
                    varThreshold=30,  # ‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
                    history=300
                )
                return []  # skip frame ‡πÅ‡∏£‡∏Å
            
            # ‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            fgmask = self._background_model.apply(gray, learningRate=0.01)
            
            # ‡∏Å‡∏£‡∏≠‡∏á noise ‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î kernel
            fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)
            fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)
            
            # ‡∏´‡∏≤ contours
            contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            detections = []
            current_time = time.time()
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô
                if 800 < area < 80000:  # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ä‡πà‡∏ß‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô
                    x, y, w, h = cv2.boundingRect(contour)
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì aspect ratio
                    aspect_ratio = w / h if h > 0 else 1
                    
                    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏´‡∏ô - ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô
                    if area > 5000 and 0.2 < aspect_ratio < 1.5:  # ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏ô
                        object_type = 'person'
                        object_name = '‡∏Ñ‡∏ô (‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß)'
                        priority = 'CRITICAL'
                        color = (255, 0, 0)
                        confidence = min(0.85, (area / 15000) + 0.5)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° confidence ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô
                    elif area > 2000 and 0.4 < aspect_ratio < 2.5:
                        object_type = 'animal'
                        object_name = '‡∏™‡∏±‡∏ï‡∏ß‡πå (‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß)'
                        priority = 'HIGH'
                        color = (255, 165, 0)
                        confidence = min(0.75, (area / 8000) + 0.4)
                    else:
                        object_type = 'unknown'
                        object_name = '‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß'
                        priority = 'MEDIUM'
                        color = (255, 255, 0)
                        confidence = min(0.65, (area / 5000) + 0.3)
                    
                    # ‡πÄ‡∏ä‡πá‡∏Ñ cooldown
                    cooldown_key = f"motion_{object_type}_{x//50}_{y//50}"  # ‡∏•‡∏î precision ‡∏Ç‡∏≠‡∏á position
                    if (cooldown_key not in self.last_detection_time or 
                        current_time - self.last_detection_time[cooldown_key] > self.cooldown_seconds):
                        
                        detection = {
                            'object_type': object_type,
                            'object_name': object_name,
                            'confidence': confidence,
                            'priority': priority,
                            'color': color,
                            'bbox': (x, y, w, h),
                            'center': (x + w//2, y + h//2),
                            'timestamp': datetime.now().isoformat(),
                            'source': 'motion'
                        }
                        
                        detections.append(detection)
                        self.last_detection_time[cooldown_key] = current_time
                        
                        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á database ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ CRITICAL ‡πÅ‡∏•‡∏∞ HIGH ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
                        if priority in ['CRITICAL', 'HIGH']:
                            self._save_alert_to_db(detection, frame)
                            
                            # ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô Chatbot
                            self._notify_chatbot(detection)
            
            return detections
            
        except Exception as e:
            print(f"‚ö†Ô∏è Motion detection error: {e}")
            return []
    
    def _remove_duplicate_detections(self, detections: List[Dict]) -> List[Dict]:
        """‡∏•‡∏ö detection ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô (overlapping bboxes)"""
        if len(detections) <= 1:
            return detections
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° confidence
        detections.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        
        filtered = []
        for detection in detections:
            bbox1 = detection['bbox']
            is_duplicate = False
            
            for existing in filtered:
                bbox2 = existing['bbox']
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì IoU (Intersection over Union)
                iou = self._calculate_iou(bbox1, bbox2)
                
                # ‡∏ñ‡πâ‡∏≤ overlap ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50% ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ã‡πâ‡∏≥
                if iou > 0.5:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                filtered.append(detection)
        
        return filtered
    
    def _calculate_iou(self, bbox1: tuple, bbox2: tuple) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Intersection over Union ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 bounding boxes"""
        x1, y1, w1, h1 = bbox1
        x2, y2, w2, h2 = bbox2
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà intersection
        xi1 = max(x1, x2)
        yi1 = max(y1, y2)
        xi2 = min(x1 + w1, x2 + w2)
        yi2 = min(y1 + h1, y2 + h2)
        
        if xi2 <= xi1 or yi2 <= yi1:
            return 0.0
        
        intersection = (xi2 - xi1) * (yi2 - yi1)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà union
        area1 = w1 * h1
        area2 = w2 * h2
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _detect_snake_like_shapes(self, frame: np.ndarray) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏á‡∏π‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏ó‡∏£‡∏á"""
        try:
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô grayscale
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # ‡πÉ‡∏ä‡πâ edge detection
            edges = cv2.Canny(gray, 50, 150)
            
            # ‡∏´‡∏≤ contours
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            snake_detections = []
            current_time = time.time()
            
            for contour in contours:
                # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÑ‡∏°‡πà‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡πÑ‡∏°‡πà‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)
                area = cv2.contourArea(contour)
                if area < 200 or area > 5000:
                    continue
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì aspect ratio
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = max(w, h) / min(w, h)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏ó‡∏£‡∏á‡∏¢‡∏≤‡∏ß‡πÜ ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏á‡∏π‡πÑ‡∏´‡∏°
                if aspect_ratio > 4:  # ‡∏¢‡∏≤‡∏ß‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏ß‡πâ‡∏≤‡∏á 4 ‡πÄ‡∏ó‡πà‡∏≤
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏á
                    perimeter = cv2.arcLength(contour, True)
                    if perimeter > 0:
                        circularity = 4 * np.pi * area / (perimeter * perimeter)
                        
                        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏á‡∏Å‡∏•‡∏° (circularity ‡∏ï‡πà‡∏≥) ‡πÅ‡∏•‡∏∞‡∏¢‡∏≤‡∏ß = ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏á‡∏π
                        if circularity < 0.3:  # ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏á‡∏Å‡∏•‡∏°
                            cooldown_key = f"snake_{x}_{y}"
                            if (cooldown_key not in self.last_detection_time or 
                                current_time - self.last_detection_time[cooldown_key] > self.cooldown_seconds * 2):
                                
                                detection = {
                                    'object_type': 'snake',
                                    'object_name': '‡∏á‡∏π (‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏ó‡∏£‡∏á)',
                                    'confidence': min(0.7, aspect_ratio / 10),  # confidence ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
                                    'priority': 'CRITICAL',
                                    'color': (128, 0, 128),
                                    'bbox': (x, y, w, h),
                                    'center': (x + w//2, y + h//2),
                                    'timestamp': datetime.now().isoformat()
                                }
                                
                                snake_detections.append(detection)
                                self.last_detection_time[cooldown_key] = current_time
                                
                                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á database
                                self._save_alert_to_db(detection, frame)
            
            return snake_detections
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏á‡∏π: {e}")
            return []
    
    def _save_alert_to_db(self, detection: Dict, frame: np.ndarray):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        try:
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            image_filename = f"alert_{detection['object_type']}_{timestamp}.jpg"
            image_path = os.path.join("anomaly_images", image_filename)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            os.makedirs("anomaly_images", exist_ok=True)
            
            # ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏≠‡∏ö‡πÜ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
            x, y, w, h = detection['bbox']
            margin = 50
            y1 = max(0, y - margin)
            y2 = min(frame.shape[0], y + h + margin)
            x1 = max(0, x - margin)
            x2 = min(frame.shape[1], x + w + margin)
            
            cropped_frame = frame[y1:y2, x1:x2]
            cv2.imwrite(image_path, cropped_frame)
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á database
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO object_alerts 
                (timestamp, object_type, object_name, confidence, priority, 
                 bbox_x, bbox_y, bbox_width, bbox_height, image_path)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                detection['timestamp'],
                detection['object_type'],
                detection['object_name'],
                detection['confidence'],
                detection['priority'],
                detection['bbox'][0],
                detection['bbox'][1],
                detection['bbox'][2],
                detection['bbox'][3],
                image_path
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}")
    
    def draw_detections(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """‡∏ß‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ö‡∏ô‡πÄ‡∏ü‡∏£‡∏°"""
        result_frame = frame.copy()
        
        for detection in detections:
            x, y, w, h = detection['bbox']
            color = detection['color']
            object_name = detection['object_name']
            confidence = detection['confidence']
            priority = detection['priority']
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö
            thickness = 3 if priority == 'CRITICAL' else 2
            cv2.rectangle(result_frame, (x, y), (x + w, y + h), color, thickness)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            label = f"{object_name} {confidence:.1%}"
            if priority == 'CRITICAL':
                label = f"üö® {label}"
            elif priority == 'HIGH':
                label = f"‚ö†Ô∏è {label}"
            
            # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2
            )
            cv2.rectangle(result_frame, (x, y - text_height - 10), 
                         (x + text_width, y), color, -1)
            
            # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            cv2.putText(result_frame, label, (x, y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return result_frame
    
    def get_recent_alerts(self, limit: int = 10) -> List[Dict]:
        """‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM object_alerts 
                ORDER BY timestamp DESC 
                LIMIT ?
            ''', (limit,))
            
            rows = cursor.fetchall()
            conn.close()
            
            alerts = []
            for row in rows:
                alerts.append({
                    'id': row[0],
                    'timestamp': row[1],
                    'object_type': row[2],
                    'object_name': row[3],
                    'confidence': row[4],
                    'priority': row[5],
                    'bbox': (row[6], row[7], row[8], row[9]),
                    'image_path': row[10],
                    'status': row[11]
                })
            
            return alerts
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
            return []
    
    def get_stats(self) -> Dict:
        """‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
            cursor.execute('''
                SELECT object_name, priority, COUNT(*) as count
                FROM object_alerts 
                WHERE date(timestamp) = date('now')
                GROUP BY object_name, priority
                ORDER BY count DESC
            ''')
            
            today_stats = cursor.fetchall()
            
            # ‡∏ô‡∏±‡∏ö‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            cursor.execute('SELECT COUNT(*) FROM object_alerts')
            total_alerts = cursor.fetchone()[0]
            
            # ‡∏ô‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ
            cursor.execute('''
                SELECT COUNT(*) FROM object_alerts 
                WHERE date(timestamp) = date('now')
            ''')
            today_total = cursor.fetchone()[0]
            
            conn.close()
            
            return {
                'total_alerts': total_alerts,
                'today_total': today_total,
                'today_by_type': today_stats,
                'last_updated': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥: {e}")
            return {'total_alerts': 0, 'today_total': 0, 'today_by_type': []}
    
    def get_recent_alerts(self, limit: int = 10) -> List[Dict]:
        """‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT timestamp, object_type, object_name, confidence, priority,
                       bbox_x, bbox_y, bbox_width, bbox_height, image_path
                FROM object_alerts 
                ORDER BY timestamp DESC 
                LIMIT ?
            ''', (limit,))
            
            alerts = []
            for row in cursor.fetchall():
                alerts.append({
                    'timestamp': row[0],
                    'object_type': row[1],
                    'object_name': row[2],
                    'confidence': row[3],
                    'priority': row[4],
                    'bbox': {
                        'x': row[5],
                        'y': row[6],
                        'width': row[7],
                        'height': row[8]
                    },
                    'image_path': row[9]
                })
            
            conn.close()
            return alerts
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: {e}")
            return []

# üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
if __name__ == "__main__":
    print("üöÄ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Advanced Object Detection System")
    
    detector = AdvancedObjectDetector()
    
    if detector.model:
        print("‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
        print(f"üìä ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ {len(detector.critical_objects)} ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏")
        
        for obj_type, info in detector.critical_objects.items():
            priority_emoji = "üö®" if info['priority'] == 'CRITICAL' else "‚ö†Ô∏è" if info['priority'] == 'HIGH' else "‚ÑπÔ∏è"
            print(f"   {priority_emoji} {info['name']} ({info['priority']})")
    else:
        print("‚ùå ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°")
