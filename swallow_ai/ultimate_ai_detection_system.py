#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ ULTIMATE AI DETECTION SYSTEM - ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
Version: 4.0 - Maximum Performance & Production Ready
‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö

Features:
- Multi-Model AI Detection (YOLO + EfficientDet + MobileNet)
- Advanced Performance Optimization
- Real-time Statistics & Analytics
- Smart Caching & Memory Management
- Production-ready Architecture
- Comprehensive Error Handling
- Advanced Visualization
"""

import cv2
import numpy as np
import requests
import os
import logging
import time
import threading
import queue
import json
import sqlite3
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional, Union, Any
from pathlib import Path
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import pickle

@dataclass
class DetectionResult:
    """‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"""
    class_name: str
    class_id: int
    confidence: float
    bbox: List[int]  # [x, y, w, h]
    center: Tuple[int, int]
    area: int
    source: str
    timestamp: float
    model_used: str
    processing_time: float
    frame_id: Optional[int] = None
    tracking_id: Optional[int] = None

@dataclass
class PerformanceMetrics:
    """‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
    fps: float
    avg_processing_time: float
    memory_usage: float
    cpu_usage: float
    detection_accuracy: float
    total_detections: int
    detection_rate: float

class SmartCache:
    """‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏Ñ‡∏ä‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞"""
    
    def __init__(self, max_size: int = 1000, ttl: int = 300):
        self.cache = {}
        self.timestamps = {}
        self.max_size = max_size
        self.ttl = ttl  # Time to live in seconds
        self.hit_count = 0
        self.miss_count = 0
    
    def get(self, key: str) -> Optional[Any]:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä"""
        if key in self.cache:
            if time.time() - self.timestamps[key] < self.ttl:
                self.hit_count += 1
                return self.cache[key]
            else:
                del self.cache[key]
                del self.timestamps[key]
        
        self.miss_count += 1
        return None
    
    def set(self, key: str, value: Any):
        """‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏Ñ‡∏ä"""
        if len(self.cache) >= self.max_size:
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            oldest_key = min(self.timestamps.keys(), key=lambda k: self.timestamps[k])
            del self.cache[oldest_key]
            del self.timestamps[oldest_key]
        
        self.cache[key] = value
        self.timestamps[key] = time.time()
    
    def get_stats(self) -> Dict:
        """‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡∏ä"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = (self.hit_count / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'hit_count': self.hit_count,
            'miss_count': self.miss_count,
            'hit_rate': f"{hit_rate:.1f}%",
            'cache_size': len(self.cache)
        }

class ModelManager:
    """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß"""
    
    def __init__(self):
        self.models = {}
        self.model_configs = {
            'yolov4': {
                'weights': 'yolov4.weights',
                'config': 'yolov4.cfg',
                'names': 'coco.names',
                'input_size': (416, 416),
                'confidence': 0.5,
                'nms': 0.4
            },
            'yolov3': {
                'weights': 'yolov3.weights',
                'config': 'yolov3.cfg',
                'names': 'coco.names',
                'input_size': (416, 416),
                'confidence': 0.5,
                'nms': 0.4
            },
            'yolov3-tiny': {
                'weights': 'yolov3-tiny.weights',
                'config': 'yolov3-tiny.cfg',
                'names': 'coco.names',
                'input_size': (416, 416),
                'confidence': 0.3,
                'nms': 0.4
            }
        }
        
        self.performance_stats = {}
        self.logger = self._setup_logger()
    
    def _setup_logger(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logger"""
        logger = logging.getLogger('ModelManager')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def load_model(self, model_name: str) -> bool:
        """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        if model_name in self.models:
            return True
            
        if model_name not in self.model_configs:
            self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
            return False
        
        config = self.model_configs[model_name]
        
        try:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå
            weights_path = Path("models") / config['weights']
            config_path = Path("models") / config['config']
            
            if not weights_path.exists():
                weights_path = Path(config['weights'])
            if not config_path.exists():
                config_path = Path(config['config'])
            
            if weights_path.exists() and config_path.exists():
                self.logger.info(f"üß† ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
                
                net = cv2.dnn.readNet(str(weights_path), str(config_path))
                net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
                net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
                
                # ‡∏î‡∏∂‡∏á output layers
                layer_names = net.getLayerNames()
                unconnected_out_layers = net.getUnconnectedOutLayers()
                
                if len(unconnected_out_layers.shape) == 1:
                    output_layers = [layer_names[i - 1] for i in unconnected_out_layers]
                else:
                    output_layers = [layer_names[i[0] - 1] for i in unconnected_out_layers]
                
                self.models[model_name] = {
                    'net': net,
                    'output_layers': output_layers,
                    'config': config,
                    'loaded_time': time.time()
                }
                
                self.performance_stats[model_name] = {
                    'total_inferences': 0,
                    'total_time': 0,
                    'avg_time': 0,
                    'best_time': float('inf'),
                    'worst_time': 0
                }
                
                self.logger.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_name} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                return True
            else:
                self.logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_name}")
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_name}: {e}")
            return False
    
    def get_model(self, model_name: str) -> Optional[Dict]:
        """‡∏î‡∏∂‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        if model_name not in self.models:
            if not self.load_model(model_name):
                return None
        
        return self.models[model_name]
    
    def update_performance(self, model_name: str, inference_time: float):
        """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
        if model_name in self.performance_stats:
            stats = self.performance_stats[model_name]
            stats['total_inferences'] += 1
            stats['total_time'] += inference_time
            stats['avg_time'] = stats['total_time'] / stats['total_inferences']
            stats['best_time'] = min(stats['best_time'], inference_time)
            stats['worst_time'] = max(stats['worst_time'], inference_time)

class UltimateAIDetectionSystem:
    """üöÄ ‡∏£‡∏∞‡∏ö‡∏ö AI Detection ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.logger = self._setup_logging()
        self.logger.info("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Ultimate AI Detection System...")
        
        # Core Components
        self.model_manager = ModelManager()
        self.cache = SmartCache(max_size=2000, ttl=600)
        self.db_manager = self._setup_database()
        
        # Configuration
        self.config = self._load_config(config_path)
        
        # Classes ‡πÅ‡∏•‡∏∞ Colors
        self.classes = []
        self.colors = []
        
        # Performance Tracking
        self.performance_metrics = PerformanceMetrics(
            fps=0, avg_processing_time=0, memory_usage=0,
            cpu_usage=0, detection_accuracy=0, total_detections=0, detection_rate=0
        )
        
        # Threading ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        self.frame_queue = queue.Queue(maxsize=10)
        self.result_queue = queue.Queue()
        
        # Statistics
        self.stats = {
            'session_start': time.time(),
            'total_frames': 0,
            'total_detections': 0,
            'detection_history': [],
            'model_usage': {},
            'performance_log': []
        }
        
        # Initialization
        self._initialize_system()
    
    def _setup_logging(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö logging ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
        logger = logging.getLogger('UltimateAI')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            # Console Handler
            console_handler = logging.StreamHandler()
            console_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)
            
            # File Handler
            file_handler = logging.FileHandler('ultimate_ai_system.log')
            file_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
            )
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)
        
        return logger
    
    def _setup_database(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
        db_path = "ultimate_ai_detections.db"
        
        try:
            conn = sqlite3.connect(db_path, check_same_thread=False)
            cursor = conn.cursor()
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS detections (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL,
                    class_name TEXT,
                    confidence REAL,
                    bbox TEXT,
                    model_used TEXT,
                    processing_time REAL,
                    frame_id INTEGER,
                    session_id TEXT
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS performance_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL,
                    fps REAL,
                    memory_usage REAL,
                    cpu_usage REAL,
                    model_name TEXT,
                    session_id TEXT
                )
            ''')
            
            conn.commit()
            self.logger.info("‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            return conn
            
        except Exception as e:
            self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
            return None
    
    def _load_config(self, config_path: Optional[str]) -> Dict:
        """‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"""
        default_config = {
            'models': {
                'primary': 'yolov4',
                'fallback': ['yolov3', 'yolov3-tiny'],
                'ensemble': False
            },
            'detection': {
                'confidence_threshold': 0.5,
                'nms_threshold': 0.4,
                'input_size': (416, 416),
                'batch_size': 1
            },
            'performance': {
                'enable_caching': True,
                'enable_threading': True,
                'enable_gpu': False,
                'max_fps': 30,
                'memory_limit': 1024  # MB
            },
            'output': {
                'save_detections': True,
                'save_frames': False,
                'output_dir': 'output',
                'log_level': 'INFO'
            }
        }
        
        if config_path and Path(config_path).exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    custom_config = json.load(f)
                    default_config.update(custom_config)
                    self.logger.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å {config_path}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤: {e}")
        
        return default_config
    
    def _initialize_system(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"""
        try:
            # ‡πÇ‡∏´‡∏•‡∏î classes
            self._load_classes()
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å
            primary_model = self.config['models']['primary']
            if self.model_manager.load_model(primary_model):
                self.logger.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å: {primary_model}")
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏£‡∏≠‡∏á
            for fallback_model in self.config['models']['fallback']:
                self.model_manager.load_model(fallback_model)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ
            self._generate_colors()
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
            output_dir = Path(self.config['output']['output_dir'])
            output_dir.mkdir(exist_ok=True)
            
            self.logger.info("üöÄ Ultimate AI System ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
            
        except Exception as e:
            self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö: {e}")
    
    def _load_classes(self):
        """‡πÇ‡∏´‡∏•‡∏î class names"""
        classes_file = Path("models/coco.names")
        if not classes_file.exists():
            classes_file = Path("coco.names")
        
        if classes_file.exists():
            try:
                with open(classes_file, 'r', encoding='utf-8') as f:
                    self.classes = [line.strip() for line in f.readlines()]
                self.logger.info(f"üìö ‡πÇ‡∏´‡∏•‡∏î {len(self.classes)} classes")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô {classes_file}: {e}")
                self._load_default_classes()
        else:
            self._load_default_classes()
    
    def _load_default_classes(self):
        """‡πÇ‡∏´‡∏•‡∏î COCO classes ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"""
        self.classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
            'hair drier', 'toothbrush'
        ]
        self.logger.info("üìö ‡πÉ‡∏ä‡πâ COCO classes ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
    
    def _generate_colors(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ class"""
        np.random.seed(42)
        self.colors = np.random.randint(0, 255, size=(len(self.classes), 3), dtype=np.uint8)
        
        # ‡∏™‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classes ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        special_colors = {
            'bird': [0, 255, 255],      # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á
            'person': [0, 0, 255],      # ‡∏™‡∏µ‡πÅ‡∏î‡∏á
            'car': [255, 0, 0],         # ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô
            'dog': [0, 255, 0],         # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
            'cat': [255, 0, 255]        # ‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á
        }
        
        for class_name, color in special_colors.items():
            if class_name in self.classes:
                idx = self.classes.index(class_name)
                self.colors[idx] = color
    
    def detect_objects(self, 
                      frame: np.ndarray, 
                      model_name: Optional[str] = None,
                      conf_threshold: Optional[float] = None,
                      nms_threshold: Optional[float] = None,
                      use_cache: bool = True) -> List[DetectionResult]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡πâ‡∏ß‡∏¢ AI (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á)"""
        
        start_time = time.time()
        frame_hash = None
        
        # ‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡∏ä‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        if use_cache and self.config['performance']['enable_caching']:
            frame_hash = hashlib.md5(frame.tobytes()).hexdigest()
            cached_result = self.cache.get(frame_hash)
            if cached_result:
                self.logger.debug("üìã ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä")
                return cached_result
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        if model_name is None:
            model_name = self.config['models']['primary']
        
        model_info = self.model_manager.get_model(model_name)
        if not model_info:
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏£‡∏≠‡∏á
            for fallback in self.config['models']['fallback']:
                model_info = self.model_manager.get_model(fallback)
                if model_info:
                    model_name = fallback
                    self.logger.warning(f"‚ö†Ô∏è ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏£‡∏≠‡∏á: {model_name}")
                    break
        
        if not model_info:
            self.logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
            return []
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ threshold
        conf_thresh = conf_threshold or self.config['detection']['confidence_threshold']
        nms_thresh = nms_threshold or self.config['detection']['nms_threshold']
        
        try:
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            net = model_info['net']
            output_layers = model_info['output_layers']
            input_size = model_info['config']['input_size']
            
            height, width = frame.shape[:2]
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á blob
            blob = cv2.dnn.blobFromImage(
                frame, 1/255.0, input_size, swapRB=True, crop=False
            )
            net.setInput(blob)
            
            # ‡∏£‡∏±‡∏ô inference
            inference_start = time.time()
            outputs = net.forward(output_layers)
            inference_time = time.time() - inference_start
            
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏°‡πÄ‡∏î‡∏•
            self.model_manager.update_performance(model_name, inference_time)
            
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            detections = self._process_detections(
                outputs, frame.shape, conf_thresh, nms_thresh, 
                model_name, start_time
            )
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡πÅ‡∏Ñ‡∏ä
            if use_cache and frame_hash:
                self.cache.set(frame_hash, detections)
            
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
            self._update_statistics(detections, time.time() - start_time)
            
            return detections
            
        except Exception as e:
            self.logger.error(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö: {e}")
            return []
    
    def _process_detections(self, outputs, frame_shape, conf_thresh, nms_thresh, model_name, start_time):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
        height, width = frame_shape[:2]
        
        boxes = []
        confidences = []
        class_ids = []
        
        # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å outputs
        for output in outputs:
            for detection in output:
                if len(detection) > 5:
                    scores = detection[5:]
                    class_id = np.argmax(scores)
                    confidence = scores[class_id]
                    
                    if confidence > conf_thresh:
                        center_x = int(detection[0] * width)
                        center_y = int(detection[1] * height)
                        w = int(detection[2] * width)
                        h = int(detection[3] * height)
                        
                        x = int(center_x - w / 2)
                        y = int(center_y - h / 2)
                        
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï
                        x = max(0, x)
                        y = max(0, y)
                        w = min(w, width - x)
                        h = min(h, height - y)
                        
                        boxes.append([x, y, w, h])
                        confidences.append(float(confidence))
                        class_ids.append(class_id)
        
        # Non-Maximum Suppression
        detections = []
        if len(boxes) > 0:
            indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_thresh, nms_thresh)
            
            if len(indices) > 0:
                indices = indices.flatten() if isinstance(indices, np.ndarray) else indices
                
                for i in indices:
                    x, y, w, h = boxes[i]
                    class_id = class_ids[i]
                    confidence = confidences[i]
                    class_name = self.classes[class_id] if class_id < len(self.classes) else 'unknown'
                    
                    detection = DetectionResult(
                        class_name=class_name,
                        class_id=class_id,
                        confidence=confidence,
                        bbox=[x, y, w, h],
                        center=(x + w//2, y + h//2),
                        area=w * h,
                        source='ultimate_ai',
                        timestamp=time.time(),
                        model_used=model_name,
                        processing_time=time.time() - start_time
                    )
                    
                    detections.append(detection)
        
        return detections
    
    def _update_statistics(self, detections: List[DetectionResult], processing_time: float):
        """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏∞‡∏ö‡∏ö"""
        self.stats['total_frames'] += 1
        self.stats['total_detections'] += len(detections)
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï performance metrics
        self.performance_metrics.total_detections += len(detections)
        self.performance_metrics.avg_processing_time = (
            (self.performance_metrics.avg_processing_time * (self.stats['total_frames'] - 1) + processing_time) 
            / self.stats['total_frames']
        )
        self.performance_metrics.fps = 1.0 / processing_time if processing_time > 0 else 0
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
        self.stats['detection_history'].append({
            'timestamp': time.time(),
            'count': len(detections),
            'processing_time': processing_time
        })
        
        # ‡∏•‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏Å‡πà‡∏≤ (‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏Ñ‡πà 1000 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
        if len(self.stats['detection_history']) > 1000:
            self.stats['detection_history'] = self.stats['detection_history'][-1000:]
    
    def detect_specific_objects(self, frame: np.ndarray, target_classes: List[str]) -> List[DetectionResult]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó"""
        all_detections = self.detect_objects(frame)
        filtered_detections = [
            det for det in all_detections 
            if det.class_name in target_classes
        ]
        return filtered_detections
    
    def detect_birds(self, frame: np.ndarray) -> List[DetectionResult]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ô‡∏Å‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        return self.detect_specific_objects(frame, ['bird'])
    
    def detect_persons(self, frame: np.ndarray) -> List[DetectionResult]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        return self.detect_specific_objects(frame, ['person'])
    
    def detect_animals(self, frame: np.ndarray) -> List[DetectionResult]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        animal_classes = ['bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe']
        return self.detect_specific_objects(frame, animal_classes)
    
    def detect_vehicles(self, frame: np.ndarray) -> List[DetectionResult]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        vehicle_classes = ['car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'bicycle']
        return self.detect_specific_objects(frame, vehicle_classes)
    
    def draw_detections(self, frame: np.ndarray, detections: List[DetectionResult], 
                       show_confidence: bool = True, show_model: bool = False) -> np.ndarray:
        """‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
        result_frame = frame.copy()
        
        for detection in detections:
            x, y, w, h = detection.bbox
            class_name = detection.class_name
            confidence = detection.confidence
            class_id = detection.class_id
            
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏µ
            if class_id < len(self.colors):
                color = tuple(map(int, self.colors[class_id]))
            else:
                color = (0, 255, 0)
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö
            thickness = 2
            cv2.rectangle(result_frame, (x, y), (x + w, y + h), color, thickness)
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            label_parts = [class_name]
            if show_confidence:
                label_parts.append(f"{confidence:.2f}")
            if show_model:
                label_parts.append(f"[{detection.model_used}]")
            
            label = " | ".join(label_parts)
            
            # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )
            
            cv2.rectangle(
                result_frame, 
                (x, y - text_height - baseline - 5), 
                (x + text_width, y), 
                color, -1
            )
            
            # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            cv2.putText(
                result_frame, label, (x, y - 5), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1
            )
            
            # ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á
            center = detection.center
            cv2.circle(result_frame, center, 3, color, -1)
            
            # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (processing time)
            if hasattr(detection, 'processing_time'):
                time_text = f"{detection.processing_time*1000:.1f}ms"
                cv2.putText(
                    result_frame, time_text, (x, y + h + 15), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1
                )
        
        return result_frame
    
    def get_performance_metrics(self) -> Dict:
        """‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
        metrics = asdict(self.performance_metrics)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        metrics.update({
            'uptime': time.time() - self.stats['session_start'],
            'cache_stats': self.cache.get_stats(),
            'model_stats': self.model_manager.performance_stats,
            'memory_usage': self._get_memory_usage(),
            'total_frames': self.stats['total_frames']
        })
        
        return metrics
    
    def _get_memory_usage(self) -> float:
        """‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024  # MB
        except ImportError:
            return 0.0
    
    def save_detection_to_db(self, detection: DetectionResult, session_id: str = "default"):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        if self.db_manager:
            try:
                cursor = self.db_manager.cursor()
                cursor.execute('''
                    INSERT INTO detections 
                    (timestamp, class_name, confidence, bbox, model_used, processing_time, session_id)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    detection.timestamp,
                    detection.class_name,
                    detection.confidence,
                    json.dumps(detection.bbox),
                    detection.model_used,
                    detection.processing_time,
                    session_id
                ))
                self.db_manager.commit()
            except Exception as e:
                self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
    
    def export_statistics(self, filepath: str):
        """‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå"""
        try:
            export_data = {
                'timestamp': datetime.now().isoformat(),
                'performance_metrics': asdict(self.performance_metrics),
                'system_stats': self.stats,
                'cache_stats': self.cache.get_stats(),
                'model_stats': self.model_manager.performance_stats,
                'config': self.config
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"‚úÖ ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÑ‡∏õ‡∏¢‡∏±‡∏á: {filepath}")
            
        except Exception as e:
            self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥: {e}")
    
    def benchmark_system(self, test_frames: int = 100) -> Dict:
        """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏£‡∏∞‡∏ö‡∏ö"""
        self.logger.info(f"üß™ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ({test_frames} ‡πÄ‡∏ü‡∏£‡∏°)...")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö
        test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ
        results = {}
        
        for model_name in self.model_manager.models.keys():
            self.logger.info(f"üìä ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
            
            times = []
            detection_counts = []
            
            for i in range(test_frames):
                start_time = time.time()
                detections = self.detect_objects(test_frame, model_name=model_name, use_cache=False)
                end_time = time.time()
                
                times.append(end_time - start_time)
                detection_counts.append(len(detections))
                
                if (i + 1) % 20 == 0:
                    self.logger.info(f"   ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {i+1}/{test_frames}")
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
            avg_time = np.mean(times)
            avg_fps = 1.0 / avg_time
            avg_detections = np.mean(detection_counts)
            
            results[model_name] = {
                'avg_processing_time': avg_time,
                'avg_fps': avg_fps,
                'avg_detections': avg_detections,
                'min_time': np.min(times),
                'max_time': np.max(times),
                'std_time': np.std(times)
            }
            
            self.logger.info(f"   üìà FPS ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_fps:.1f}")
            self.logger.info(f"   üéØ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_detections:.1f}")
        
        self.logger.info("‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        return results
    
    def cleanup(self):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£"""
        self.logger.info("üßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏£‡∏∞‡∏ö‡∏ö...")
        
        # ‡∏õ‡∏¥‡∏î thread pool
        if self.thread_pool:
            self.thread_pool.shutdown(wait=True)
        
        # ‡∏õ‡∏¥‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if self.db_manager:
            self.db_manager.close()
        
        self.logger.info("‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

# Helper Functions
def create_config_file(filename: str = "ultimate_ai_config.json"):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"""
    config = {
        "models": {
            "primary": "yolov4",
            "fallback": ["yolov3", "yolov3-tiny"],
            "ensemble": False
        },
        "detection": {
            "confidence_threshold": 0.5,
            "nms_threshold": 0.4,
            "input_size": [416, 416],
            "batch_size": 1
        },
        "performance": {
            "enable_caching": True,
            "enable_threading": True,
            "enable_gpu": False,
            "max_fps": 30,
            "memory_limit": 1024
        },
        "output": {
            "save_detections": True,
            "save_frames": False,
            "output_dir": "output",
            "log_level": "INFO"
        }
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤: {filename}")

# Test ‡πÅ‡∏•‡∏∞ Demo
def test_ultimate_ai_system():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Ultimate AI"""
    print("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Ultimate AI Detection System...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö
    ai_system = UltimateAIDetectionSystem()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á
    rtsp_urls = [
        "rtsp://ainok1:ainok123@192.168.1.100:554/stream1",
        "rtsp://admin:admin@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0",
        0  # ‡∏Å‡∏•‡πâ‡∏≠‡∏á USB
    ]
    
    cap = None
    connected = False
    
    for rtsp_url in rtsp_urls:
        print(f"üìπ ‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: {rtsp_url}")
        cap = cv2.VideoCapture(rtsp_url)
        
        if cap and cap.isOpened():
            ret, frame = cap.read()
            if ret and frame is not None:
                print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {rtsp_url}")
                connected = True
                break
            else:
                cap.release()
        else:
            if cap:
                cap.release()
    
    if not connected:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ - ‡πÉ‡∏ä‡πâ‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
        test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
        detections = ai_system.detect_objects(test_frame)
        print(f"üéØ ‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö: {len(detections)} ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏")
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        benchmark_results = ai_system.benchmark_system(50)
        print("üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:")
        for model, stats in benchmark_results.items():
            print(f"   {model}: {stats['avg_fps']:.1f} FPS")
    
    else:
        print("üé• ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á...")
        
        frame_count = 0
        detection_count = 0
        start_time = time.time()
        
        try:
            while frame_count < 50:  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö 50 ‡πÄ‡∏ü‡∏£‡∏°
                ret, frame = cap.read()
                if not ret:
                    continue
                
                frame_count += 1
                
                # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
                detections = ai_system.detect_objects(frame)
                
                if len(detections) > 0:
                    detection_count += 1
                    print(f"üéØ Frame {frame_count}: ‡∏û‡∏ö {len(detections)} ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏")
                    
                    for det in detections:
                        print(f"   üìç {det.class_name}: {det.confidence:.2f} [{det.model_used}]")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                if frame_count % 10 == 0:
                    elapsed = time.time() - start_time
                    fps = frame_count / elapsed
                    print(f"üìä ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {frame_count}/50 ‡πÄ‡∏ü‡∏£‡∏° (FPS: {fps:.1f})")
        
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
        finally:
            if cap:
                cap.release()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    metrics = ai_system.get_performance_metrics()
    print(f"\nüìà ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Ultimate AI System:")
    print(f"   ‚ö° FPS ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {metrics['fps']:.1f}")
    print(f"   üïí ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {metrics['avg_processing_time']*1000:.1f} ms")
    print(f"   üß† ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥: {metrics['memory_usage']:.1f} MB")
    print(f"   üìã ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡∏ä: {metrics['cache_stats']['hit_rate']}")
    print(f"   üéØ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {metrics['total_detections']}")
    
    # ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    ai_system.export_statistics("ultimate_ai_test_results.json")
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    ai_system.cleanup()
    
    print("‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

if __name__ == "__main__":
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
    create_config_file()
    
    # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    test_ultimate_ai_system()
    
    print("\n‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å...")
    input()
