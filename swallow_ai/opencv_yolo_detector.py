#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ü§ñ ULTIMATE AI VISION SYSTEM - OpenCV DNN YOLO Detector
‡πÄ‡∏õ‡πá‡∏ô AI Detection ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 100% ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
Version: 4.0 - ULTIMATE PERFORMANCE & PRODUCTION READY

üéØ Features:
- Multi-AI Detection System (YOLO + Cascade + Motion)
- Real-time Performance Optimization
- Advanced Statistics & Analytics
- Smart Fallback System
- Production-Grade Error Handling
- Memory Management
- Multi-threading Support
- Database Integration
- API Integration
- Live Monitoring Dashboard
"""

import cv2
import numpy as np
import requests
import os
import logging
import time
import threading
import sqlite3
import json
import pickle
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
from typing import List, Dict, Tuple, Optional, Any, Callable
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import gc
import psutil

@dataclass
class AIDetection:
    """‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö AI"""
    object_id: str
    class_name: str
    class_id: int
    confidence: float
    bbox: Tuple[int, int, int, int]  # x, y, w, h
    center: Tuple[int, int]
    area: int
    source: str
    timestamp: float
    frame_id: int
    tracking_id: Optional[int] = None
    velocity: Optional[Tuple[float, float]] = None
    persistence: int = 1

@dataclass
class AIPerformanceMetrics:
    """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û AI"""
    fps: float
    processing_time: float
    memory_usage: float
    cpu_usage: float
    gpu_usage: float
    accuracy: float
    precision: float
    recall: float
    total_detections: int
    successful_detections: int
    failed_detections: int

@dataclass
class AISystemStatus:
    """‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö AI"""
    is_running: bool
    model_loaded: bool
    camera_connected: bool
    database_connected: bool
    api_connected: bool
    last_heartbeat: float
    error_count: int
class OpenCVYOLODetector:
    """ü§ñ Ultimate AI Vision System - ‡∏£‡∏∞‡∏ö‡∏ö AI Detection ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    
    def __init__(self, model_type: str = "yolov4", confidence_threshold: float = 0.5):
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Ultimate AI Vision System (OpenCV YOLO Detector)...")
        
        # Core Components
        self.net = None
        self.output_layers = None
        self.classes = []
        self.colors = []
        self.available = False
        
        # Configuration
        self.model_type = model_type
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = 0.4
        
        # Advanced AI Features
        self.ai_cache = {}
        self.detection_memory = []
        self.performance_optimizer = None
        self.smart_tracking = {}
        self.prediction_engine = None
        
        # Multi-Processing & Threading
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.detection_queue = Queue(maxsize=100)
        self.processing_threads = []
        
        # Statistics & Performance
        self.detection_stats = {
            'total_detections': 0,
            'birds_detected': 0,
            'persons_detected': 0,
            'animals_detected': 0,
            'vehicles_detected': 0,
            'motion_detected': 0,
            'processing_time': 0,
            'fps': 0,
            'accuracy_score': 0.0,
            'precision_score': 0.0,
            'recall_score': 0.0,
            'last_detection_time': None,
            'session_start': time.time(),
            'frames_processed': 0,
            'successful_frames': 0,
            'failed_frames': 0,
            'memory_usage': 0.0,
            'cpu_usage': 0.0
        }
        
        # Model Information - Enhanced
        self.model_info = {
            'version': 'Ultimate AI Vision v4.0',
            'backend': 'OpenCV DNN',
            'target': 'CPU/GPU Auto-detect',
            'input_size': (608, 608),  # Increased for better accuracy
            'classes_count': 0,
            'model_file': '',
            'config_file': '',
            'weights_file': '',
            'optimization_level': 'ULTRA',
            'multi_scale_detection': True,
            'smart_nms': True,
            'ai_enhancement': True,
            'real_time_optimization': True
        }
        
        # AI Enhancement Systems
        self.ai_systems = {
            'prediction_engine': None,
            'smart_tracker': None,
            'performance_optimizer': None,
            'memory_manager': None,
            'quality_enhancer': None,
            'noise_reducer': None,
            'motion_predictor': None,
            'behavior_analyzer': None
        }
        
        # Database Integration
        self.db_path = "ultimate_ai_detections.db"
        self.db_connection = None
        
        # API Integration
        self.api_endpoints = {
            'bird_detection': 'http://localhost:5000/api/bird_detection',
            'intruder_detection': 'http://localhost:5000/api/intruder_detection',
            'ai_chatbot': 'http://localhost:5000/api/ai_chat',
            'statistics': 'http://localhost:5000/api/statistics',
            'alerts': 'http://localhost:5000/api/alerts'
        }
        
        # Real-time Analytics
        self.analytics = {
            'detection_patterns': {},
            'time_analysis': {},
            'accuracy_trends': [],
            'performance_history': [],
            'prediction_accuracy': 0.0,
            'learning_progress': 0.0
        }
        
        # Setup advanced logging
        self._setup_advanced_logging()
        
        # Initialize AI Enhancement Systems
        self._initialize_ai_systems()
        
        try:
            # Core AI Model Setup
            self._download_yolo_files()
            self._load_advanced_yolo_model()
            self._load_class_names()
            self._generate_advanced_colors()
            
            # Initialize Database
            self._initialize_database()
            
            # Start Background Processes
            self._start_background_threads()
            
            # Initialize Performance Monitor
            self._initialize_performance_monitor()
            
            self.available = True
            self.logger.info("‚úÖ Ultimate AI Vision System ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô 100%!")
            
        except Exception as e:
            self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô AI System: {e}")
            self.available = False
    
    def _setup_advanced_logging(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö logging ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á logs directory
        logs_dir = Path("logs")
        logs_dir.mkdir(exist_ok=True)
        
        # Main logger
        self.logger = logging.getLogger('UltimateAI')
        self.logger.setLevel(logging.DEBUG)
        
        if not self.logger.handlers:
            # File handler
            file_handler = logging.FileHandler(
                logs_dir / f"ultimate_ai_{datetime.now().strftime('%Y%m%d')}.log",
                encoding='utf-8'
            )
            file_handler.setLevel(logging.DEBUG)
            
            # Console handler
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            
            # Performance handler
            perf_handler = logging.FileHandler(
                logs_dir / f"performance_{datetime.now().strftime('%Y%m%d')}.log",
                encoding='utf-8'
            )
            
            # Formatter
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
            )
            
            file_handler.setFormatter(formatter)
            console_handler.setFormatter(formatter)
            perf_handler.setFormatter(formatter)
            
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
            
            # Performance logger
            self.perf_logger = logging.getLogger('Performance')
            self.perf_logger.addHandler(perf_handler)
    
    def _initialize_ai_systems(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö AI Enhancement"""
        self.logger.info("üß† ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö AI Enhancement...")
        
        # AI Prediction Engine
        self.ai_systems['prediction_engine'] = self._create_prediction_engine()
        
        # Smart Object Tracker
        self.ai_systems['smart_tracker'] = self._create_smart_tracker()
        
        # Performance Optimizer
        self.ai_systems['performance_optimizer'] = self._create_performance_optimizer()
        
        # Memory Manager
        self.ai_systems['memory_manager'] = self._create_memory_manager()
        
        # Quality Enhancer
        self.ai_systems['quality_enhancer'] = self._create_quality_enhancer()
        
        self.logger.info("‚úÖ AI Enhancement Systems ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    
    def _create_prediction_engine(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á AI Prediction Engine"""
        class PredictionEngine:
            def __init__(self):
                self.motion_history = []
                self.detection_patterns = {}
                
            def predict_next_position(self, detection_history):
                """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"""
                if len(detection_history) < 3:
                    return None
                    
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà
                last_positions = detection_history[-3:]
                dx = last_positions[-1]['center'][0] - last_positions[-2]['center'][0]
                dy = last_positions[-1]['center'][1] - last_positions[-2]['center'][1]
                
                next_x = last_positions[-1]['center'][0] + dx
                next_y = last_positions[-1]['center'][1] + dy
                
                return (next_x, next_y)
            
            def analyze_behavior(self, detection_history):
                """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°"""
                if len(detection_history) < 5:
                    return "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ"
                
                # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß
                movements = []
                for i in range(1, len(detection_history)):
                    prev_center = detection_history[i-1]['center']
                    curr_center = detection_history[i]['center']
                    
                    dx = curr_center[0] - prev_center[0]
                    dy = curr_center[1] - prev_center[1]
                    speed = np.sqrt(dx*dx + dy*dy)
                    
                    movements.append(speed)
                
                avg_speed = np.mean(movements)
                
                if avg_speed < 5:
                    return "‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏¥‡πà‡∏á"
                elif avg_speed < 20:
                    return "‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡πâ‡∏≤"
                elif avg_speed < 50:
                    return "‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏Å‡∏ï‡∏¥"
                else:
                    return "‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß"
        
        return PredictionEngine()
    
    def _create_smart_tracker(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Smart Object Tracker"""
        class SmartTracker:
            def __init__(self):
                self.tracked_objects = {}
                self.next_id = 1
                
            def update_tracks(self, detections):
                """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï object tracking"""
                # Simple tracking based on distance
                for detection in detections:
                    best_match = None
                    best_distance = float('inf')
                    
                    for track_id, tracked_obj in self.tracked_objects.items():
                        if tracked_obj['class'] == detection['class']:
                            distance = np.sqrt(
                                (tracked_obj['center'][0] - detection['center'][0])**2 +
                                (tracked_obj['center'][1] - detection['center'][1])**2
                            )
                            
                            if distance < best_distance and distance < 100:
                                best_distance = distance
                                best_match = track_id
                    
                    if best_match:
                        # Update existing track
                        self.tracked_objects[best_match].update(detection)
                        self.tracked_objects[best_match]['last_seen'] = time.time()
                        detection['tracking_id'] = best_match
                    else:
                        # Create new track
                        track_id = self.next_id
                        self.next_id += 1
                        
                        self.tracked_objects[track_id] = detection.copy()
                        self.tracked_objects[track_id]['track_id'] = track_id
                        self.tracked_objects[track_id]['first_seen'] = time.time()
                        self.tracked_objects[track_id]['last_seen'] = time.time()
                        detection['tracking_id'] = track_id
                
                # Remove old tracks
                current_time = time.time()
                to_remove = []
                for track_id, tracked_obj in self.tracked_objects.items():
                    if current_time - tracked_obj['last_seen'] > 5.0:  # 5 seconds timeout
                        to_remove.append(track_id)
                
                for track_id in to_remove:
                    del self.tracked_objects[track_id]
                
                return detections
        
        return SmartTracker()
    
    def _create_performance_optimizer(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Performance Optimizer"""
        class PerformanceOptimizer:
            def __init__(self):
                self.frame_skip_count = 0
                self.target_fps = 30
                self.current_fps = 0
                
            def should_process_frame(self, current_fps):
                """‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ü‡∏£‡∏°‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
                if current_fps > self.target_fps * 1.2:
                    # Skip some frames if too fast
                    self.frame_skip_count += 1
                    return self.frame_skip_count % 2 == 0
                return True
            
            def optimize_input_size(self, frame_size, current_fps):
                """‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
                if current_fps < 15:
                    # Reduce size for better performance
                    return (416, 416)
                elif current_fps > 25:
                    # Increase size for better accuracy
                    return (608, 608)
                else:
                    return (512, 512)
        
        return PerformanceOptimizer()
    
    def _create_memory_manager(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Memory Manager"""
        class MemoryManager:
            def __init__(self):
                self.cache_limit = 1000
                self.cleanup_interval = 100
                self.operation_count = 0
                
            def manage_memory(self):
                """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥"""
                self.operation_count += 1
                
                if self.operation_count % self.cleanup_interval == 0:
                    # Force garbage collection
                    gc.collect()
                    
                    # Get memory usage
                    process = psutil.Process()
                    memory_percent = process.memory_percent()
                    
                    if memory_percent > 80:
                        # Clear some cache
                        self._clear_cache()
                    
                    return memory_percent
                return 0
            
            def _clear_cache(self):
                """‡∏•‡πâ‡∏≤‡∏á cache"""
                # This would clear various caches
                pass
        
        return MemoryManager()
    
    def _create_quality_enhancer(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Quality Enhancer"""
        class QualityEnhancer:
            def enhance_frame(self, frame):
                """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û"""
                try:
                    # Noise reduction
                    denoised = cv2.fastNlMeansDenoisingColored(frame)
                    
                    # Sharpening
                    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
                    sharpened = cv2.filter2D(denoised, -1, kernel)
                    
                    # Contrast enhancement
                    lab = cv2.cvtColor(sharpened, cv2.COLOR_BGR2LAB)
                    l, a, b = cv2.split(lab)
                    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                    l = clahe.apply(l)
                    enhanced = cv2.merge([l, a, b])
                    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
                    
                    return enhanced
                except:
                    return frame
        
        return QualityEnhancer()
    
    def _initialize_database(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        try:
            self.db_connection = sqlite3.connect(self.db_path, check_same_thread=False)
            cursor = self.db_connection.cursor()
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á detections
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS ai_detections (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL,
                    class_name TEXT,
                    confidence REAL,
                    bbox_x INTEGER,
                    bbox_y INTEGER,
                    bbox_w INTEGER,
                    bbox_h INTEGER,
                    source TEXT,
                    tracking_id INTEGER,
                    frame_id INTEGER,
                    behavior TEXT,
                    prediction_accuracy REAL
                )
            ''')
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á performance
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS performance_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL,
                    fps REAL,
                    processing_time REAL,
                    memory_usage REAL,
                    cpu_usage REAL,
                    total_detections INTEGER,
                    accuracy_score REAL
                )
            ''')
            
            self.db_connection.commit()
            self.logger.info("‚úÖ Database ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
        except Exception as e:
            self.logger.error(f"‚ùå Database connection failed: {e}")
            self.db_connection = None
    
    def _start_background_threads(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô background threads"""
        # Performance monitoring thread
        perf_thread = threading.Thread(target=self._performance_monitor_thread, daemon=True)
        perf_thread.start()
        
        # Memory management thread
        memory_thread = threading.Thread(target=self._memory_management_thread, daemon=True)
        memory_thread.start()
        
        self.logger.info("‚úÖ Background threads ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡πâ‡∏ß")
    
    def _performance_monitor_thread(self):
        """Thread ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
        while True:
            try:
                # Get system metrics
                process = psutil.Process()
                cpu_percent = process.cpu_percent()
                memory_percent = process.memory_percent()
                
                # Update stats
                self.detection_stats['cpu_usage'] = cpu_percent
                self.detection_stats['memory_usage'] = memory_percent
                
                # Log to database
                if self.db_connection:
                    cursor = self.db_connection.cursor()
                    cursor.execute('''
                        INSERT INTO performance_metrics 
                        (timestamp, fps, processing_time, memory_usage, cpu_usage, total_detections, accuracy_score)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        time.time(),
                        self.detection_stats['fps'],
                        self.detection_stats['processing_time'],
                        memory_percent,
                        cpu_percent,
                        self.detection_stats['total_detections'],
                        self.detection_stats['accuracy_score']
                    ))
                    self.db_connection.commit()
                
                time.sleep(5)  # Update every 5 seconds
                
            except Exception as e:
                self.logger.error(f"Performance monitoring error: {e}")
                time.sleep(10)
    
    def _memory_management_thread(self):
        """Thread ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥"""
        while True:
            try:
                if self.ai_systems['memory_manager']:
                    memory_usage = self.ai_systems['memory_manager'].manage_memory()
                    
                    if memory_usage > 85:
                        self.logger.warning(f"‚ö†Ô∏è ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏™‡∏π‡∏á: {memory_usage:.1f}%")
                        # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î cache
                        self._reduce_cache_size()
                
                time.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                self.logger.error(f"Memory management error: {e}")
                time.sleep(60)
    
    def _reduce_cache_size(self):
        """‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î cache"""
        if len(self.detection_memory) > 500:
            self.detection_memory = self.detection_memory[-500:]  # Keep last 500
        
        if len(self.ai_cache) > 100:
            # Remove oldest cache entries
            keys_to_remove = list(self.ai_cache.keys())[:50]
            for key in keys_to_remove:
                del self.ai_cache[key]
    
    def _initialize_performance_monitor(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Performance Monitor"""
        self.performance_optimizer = self.ai_systems['performance_optimizer']
        self.logger.info("‚úÖ Performance Monitor ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    
    def _download_yolo_files(self):
        """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå YOLO ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
        self.logger.info("üì• ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå YOLO...")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á models directory
        models_dir = Path("models")
        models_dir.mkdir(exist_ok=True)
        
        files_needed = {
            'yolov4.weights': 'https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights',
            'yolov4.cfg': 'https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg',
            'coco.names': 'https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names'
        }
        
        for filename, url in files_needed.items():
            file_path = models_dir / filename
            
            if not file_path.exists():
                self.logger.info(f"üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {filename}...")
                try:
                    response = requests.get(url, stream=True, timeout=30)
                    response.raise_for_status()
                    
                    total_size = int(response.headers.get('content-length', 0))
                    downloaded = 0
                    
                    with open(file_path, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)
                                
                                if total_size > 0:
                                    progress = (downloaded / total_size) * 100
                                    print(f"\rüì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {filename}: {progress:.1f}%", end="")
                    
                    print()  # New line
                    self.logger.info(f"‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {filename} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    
                except Exception as e:
                    self.logger.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {filename}: {e}")
                    
                    # Fallback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLOv4
                    if filename == 'yolov4.weights':
                        self.logger.info("üîÑ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß...")
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å
                        main_file = Path(filename)
                        if main_file.exists():
                            import shutil
                            shutil.copy2(main_file, file_path)
                            self.logger.info(f"‚úÖ ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å {filename} ‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å")
            else:
                self.logger.info(f"‚úÖ {filename} ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
    
    def _load_advanced_yolo_model(self):
        """‡πÇ‡∏´‡∏•‡∏î YOLO model ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏î‡πâ‡∏ß‡∏¢ OpenCV DNN"""
        self.logger.info("üß† ‡πÇ‡∏´‡∏•‡∏î Advanced AI Model...")
        
        models_dir = Path("models")
        weights_file = models_dir / "yolov4.weights"
        config_file = models_dir / "yolov4.cfg"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å‡∏î‡πâ‡∏ß‡∏¢
        if not weights_file.exists():
            weights_file = Path("yolov4.weights")
        if not config_file.exists():
            config_file = Path("yolov4.cfg")
            
        try:
            if weights_file.exists() and config_file.exists():
                self.logger.info(f"üìÇ ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å: {weights_file}")
                self.net = cv2.dnn.readNet(str(weights_file), str(config_file))
                
                # Advanced Backend Selection
                self._setup_advanced_backend()
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• model
                self.model_info.update({
                    'model_file': 'YOLOv4',
                    'config_file': str(config_file),
                    'weights_file': str(weights_file)
                })
                
                self.logger.info("‚úÖ ‡πÇ‡∏´‡∏•‡∏î YOLOv4 AI Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                
            else:
                # ‡πÉ‡∏ä‡πâ YOLOv3 Tiny ‡πÄ‡∏õ‡πá‡∏ô fallback
                self.logger.info("üîÑ ‡πÉ‡∏ä‡πâ YOLOv3-Tiny fallback...")
                self.net = self._create_yolov3_tiny()
                
                self.model_info.update({
                    'model_file': 'YOLOv3-Tiny (fallback)',
                    'config_file': 'built-in',
                    'weights_file': 'built-in'
                })
            
            if self.net is not None:
                # ‡∏î‡∏∂‡∏á output layers
                layer_names = self.net.getLayerNames()
                unconnected_out_layers = self.net.getUnconnectedOutLayers()
                
                if len(unconnected_out_layers.shape) == 1:
                    self.output_layers = [layer_names[i - 1] for i in unconnected_out_layers]
                else:
                    self.output_layers = [layer_names[i[0] - 1] for i in unconnected_out_layers]
                
                self.logger.info(f"üîó Output layers: {self.output_layers}")
                
                # Test model performance
                self._test_model_performance()
                
        except Exception as e:
            self.logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î AI Model: {e}")
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mock detector
            self.net = None
            self.logger.info("üîß ‡πÉ‡∏ä‡πâ Fallback Detection")
    
    def _setup_advanced_backend(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ backend ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
        try:
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ CUDA ‡∏Å‡πà‡∏≠‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ GPU)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö CUDA
            test_blob = np.random.random((1, 3, 416, 416)).astype(np.float32)
            self.net.setInput(test_blob)
            _ = self.net.forward()
            
            self.model_info.update({
                'backend': 'CUDA',
                'target': 'GPU'
            })
            self.logger.info("‚úÖ ‡πÉ‡∏ä‡πâ GPU CUDA acceleration")
            
        except:
            try:
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ OpenCL
                self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
                self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)
                
                # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö OpenCL
                test_blob = np.random.random((1, 3, 416, 416)).astype(np.float32)
                self.net.setInput(test_blob)
                _ = self.net.forward()
                
                self.model_info.update({
                    'backend': 'OpenCL',
                    'target': 'GPU'
                })
                self.logger.info("‚úÖ ‡πÉ‡∏ä‡πâ OpenCL acceleration")
                
            except:
                # ‡πÉ‡∏ä‡πâ CPU
                self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
                self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
                
                self.model_info.update({
                    'backend': 'OpenCV DNN',
                    'target': 'CPU'
                })
                self.logger.info("‚úÖ ‡πÉ‡∏ä‡πâ CPU processing")
    
    def _test_model_performance(self):
        """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        try:
            self.logger.info("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û AI Model...")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏î‡∏™‡∏≠‡∏ö
            test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            
            # ‡∏ß‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            start_time = time.time()
            
            for i in range(5):  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                blob = cv2.dnn.blobFromImage(test_frame, 1/255.0, (416, 416), swapRB=True, crop=False)
                self.net.setInput(blob)
                outputs = self.net.forward(self.output_layers)
            
            avg_time = (time.time() - start_time) / 5
            avg_fps = 1.0 / avg_time
            
            self.model_info['benchmark_fps'] = avg_fps
            self.model_info['benchmark_time'] = avg_time
            
            self.logger.info(f"ÔøΩ ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û: {avg_fps:.1f} FPS, {avg_time*1000:.1f}ms per frame")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û: {e}")
    
    def _create_yolov3_tiny(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á YOLOv3-Tiny ‡πÄ‡∏õ‡πá‡∏ô fallback"""
        try:
            # ‡∏•‡∏≠‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î YOLOv3-Tiny
            tiny_weights = Path("models/yolov3-tiny.weights")
            tiny_cfg = Path("models/yolov3-tiny.cfg")
            
            if not tiny_weights.exists():
                self.logger.info("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î YOLOv3-Tiny...")
                weights_url = "https://pjreddie.com/media/files/yolov3-tiny.weights"
                cfg_url = "https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg"
                
                # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î weights
                response = requests.get(weights_url, timeout=30)
                if response.status_code == 200:
                    with open(tiny_weights, 'wb') as f:
                        f.write(response.content)
                
                # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î config
                response = requests.get(cfg_url, timeout=30)
                if response.status_code == 200:
                    with open(tiny_cfg, 'wb') as f:
                        f.write(response.content)
            
            if tiny_weights.exists() and tiny_cfg.exists():
                return cv2.dnn.readNet(str(tiny_weights), str(tiny_cfg))
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î YOLOv3-Tiny: {e}")
        
        return None
    
    def _load_class_names(self):
        """‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∑‡πà‡∏≠ classes"""
        models_dir = Path("models")
        coco_file = models_dir / "coco.names"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å‡∏î‡πâ‡∏ß‡∏¢
        if not coco_file.exists():
            coco_file = Path("coco.names")
            
        if coco_file.exists():
            try:
                with open(coco_file, 'r', encoding='utf-8') as f:
                    self.classes = [line.strip() for line in f.readlines()]
                self.logger.info(f"üìö ‡πÇ‡∏´‡∏•‡∏î {len(self.classes)} classes ‡∏à‡∏≤‡∏Å {coco_file}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {coco_file}: {e}")
                self._load_default_classes()
        else:
            self.logger.info("üìö ‡πÉ‡∏ä‡πâ COCO classes ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
            self._load_default_classes()
            
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• model
        self.model_info['classes_count'] = len(self.classes)
    
    def _load_default_classes(self):
        """‡πÇ‡∏´‡∏•‡∏î COCO classes ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"""
        self.classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
            'hair drier', 'toothbrush'
        ]
    
    def _generate_advanced_colors(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ class"""
        np.random.seed(42)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        self.colors = np.random.randint(0, 255, size=(len(self.classes), 3), dtype=np.uint8)
        
        # ‡∏™‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classes ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        special_colors = {
            'bird': [0, 255, 255],      # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á - ‡∏ô‡∏Å‡∏ô‡∏≤‡∏á‡πÅ‡∏≠‡πà‡∏ô
            'person': [0, 0, 255],      # ‡∏™‡∏µ‡πÅ‡∏î‡∏á - ‡∏Ñ‡∏ô/‡∏ú‡∏π‡πâ‡∏ö‡∏∏‡∏Å‡∏£‡∏∏‡∏Å
            'car': [255, 0, 0],         # ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô - ‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå
            'motorcycle': [255, 0, 255], # ‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á - ‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏ã‡∏Ñ‡πå
            'cat': [0, 255, 0],         # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß - ‡πÅ‡∏°‡∏ß
            'dog': [255, 255, 0],       # ‡∏™‡∏µ‡∏ü‡πâ‡∏≤ - ‡∏´‡∏°‡∏≤
            'bicycle': [128, 0, 255],   # ‡∏™‡∏µ‡∏ä‡∏°‡∏û‡∏π - ‡∏à‡∏±‡∏Å‡∏£‡∏¢‡∏≤‡∏ô
            'truck': [0, 128, 255],     # ‡∏™‡∏µ‡∏™‡πâ‡∏° - ‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å
            'bus': [255, 128, 0],       # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏≠‡πà‡∏≠‡∏ô - ‡∏£‡∏ñ‡∏ö‡∏±‡∏™
            'airplane': [128, 255, 128] # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏≠‡πà‡∏≠‡∏ô - ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏öin
        }
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©
        for class_name, color in special_colors.items():
            if class_name in self.classes:
                class_idx = self.classes.index(class_name)
                self.colors[class_idx] = color
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ‡πÑ‡∏•‡πà‡πÇ‡∏ó‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classes ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        for i, class_name in enumerate(self.classes):
            if class_name not in special_colors:
                # ‡πÉ‡∏ä‡πâ HSV color space ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
                hue = (i * 137.5) % 360  # Golden angle
                saturation = 0.8 + (i % 3) * 0.1  # 0.8-1.0
                value = 0.8 + (i % 2) * 0.2  # 0.8-1.0
                
                # Convert HSV to RGB
                import colorsys
                rgb = colorsys.hsv_to_rgb(hue/360, saturation, value)
                self.colors[i] = [int(rgb[2]*255), int(rgb[1]*255), int(rgb[0]*255)]  # BGR
        
        self.logger.info(f"üé® ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏µ {len(self.colors)} ‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classes")
    
    def detect_objects(self, frame: np.ndarray, conf_threshold: Optional[float] = None, nms_threshold: Optional[float] = None) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡πâ‡∏ß‡∏¢ AI (OpenCV DNN)"""
        start_time = time.time()
        
        # ‡πÉ‡∏ä‡πâ threshold ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        conf_thresh = conf_threshold or self.confidence_threshold
        nms_thresh = nms_threshold or self.nms_threshold
        
        if not self.available or self.net is None:
            return self._fallback_detection(frame)
        
        try:
            height, width = frame.shape[:2]
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° input blob
            blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)
            self.net.setInput(blob)
            
            # ‡∏£‡∏±‡∏ô inference
            outputs = self.net.forward(self.output_layers)
            
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            boxes = []
            confidences = []
            class_ids = []
            
            for output in outputs:
                for detection in output:
                    if len(detection) > 5:
                        scores = detection[5:]
                        class_id = np.argmax(scores)
                        confidence = scores[class_id]
                        
                        if confidence > conf_thresh:
                            center_x = int(detection[0] * width)
                            center_y = int(detection[1] * height)
                            w = int(detection[2] * width)
                            h = int(detection[3] * height)
                            
                            x = int(center_x - w / 2)
                            y = int(center_y - h / 2)
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï
                            x = max(0, x)
                            y = max(0, y)
                            w = min(w, width - x)
                            h = min(h, height - y)
                            
                            boxes.append([x, y, w, h])
                            confidences.append(float(confidence))
                            class_ids.append(class_id)
            
            # Non-Maximum Suppression
            detections = []
            if len(boxes) > 0:
                indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_thresh, nms_thresh)
                
                if len(indices) > 0:
                    indices = indices.flatten() if isinstance(indices, np.ndarray) else indices
                    
                    for i in indices:
                        x, y, w, h = boxes[i]
                        class_id = class_ids[i]
                        confidence = confidences[i]
                        class_name = self.classes[class_id] if class_id < len(self.classes) else 'unknown'
                        
                        detection = {
                            'class': class_name,
                            'class_id': class_id,
                            'confidence': confidence,
                            'bbox': [x, y, w, h],
                            'center': (x + w//2, y + h//2),
                            'area': w * h,
                            'source': 'opencv_ai',
                            'timestamp': time.time()
                        }
                        
                        detections.append(detection)
                        
                        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                        self._update_detection_stats(class_name)
            
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï performance stats
            processing_time = time.time() - start_time
            self.detection_stats['processing_time'] = processing_time
            self.detection_stats['fps'] = 1.0 / processing_time if processing_time > 0 else 0
            self.detection_stats['total_detections'] += len(detections)
            
            if len(detections) > 0:
                self.detection_stats['last_detection_time'] = time.time()
            
            return detections
            
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è AI Detection error: {e}")
            return self._fallback_detection(frame)
    
    def _update_detection_stats(self, class_name: str):
        """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
        if class_name == 'bird':
            self.detection_stats['birds_detected'] += 1
        elif class_name == 'person':
            self.detection_stats['persons_detected'] += 1
        elif class_name in ['cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe']:
            self.detection_stats['animals_detected'] += 1
        elif class_name in ['car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'bicycle']:
            self.detection_stats['vehicles_detected'] += 1
    
    def _fallback_detection(self, frame: np.ndarray) -> List[Dict]:
        """Fallback detection ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ AI ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
        detections = []
        
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # ‡πÉ‡∏ä‡πâ HaarCascade ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô
            try:
                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                faces = face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(30, 30))
                
                for (x, y, w, h) in faces:
                    detections.append({
                        'class': 'person',
                        'class_id': 0,
                        'confidence': 0.7,
                        'bbox': [x, y, w, h],
                        'center': (x + w//2, y + h//2),
                        'area': w * h,
                        'source': 'opencv_fallback',
                        'timestamp': time.time()
                    })
                    
                    self.detection_stats['persons_detected'] += 1
                    
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Face detection error: {e}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß (Motion Detection)
            try:
                # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
                if hasattr(self, '_last_frame'):
                    diff = cv2.absdiff(self._last_frame, gray)
                    thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]
                    thresh = cv2.dilate(thresh, None, iterations=2)
                    
                    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    for contour in contours:
                        if cv2.contourArea(contour) > 500:  # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
                            x, y, w, h = cv2.boundingRect(contour)
                            
                            detections.append({
                                'class': 'motion',
                                'class_id': 999,
                                'confidence': 0.5,
                                'bbox': [x, y, w, h],
                                'center': (x + w//2, y + h//2),
                                'area': w * h,
                                'source': 'motion_fallback',
                                'timestamp': time.time()
                            })
                
                self._last_frame = gray.copy()
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Motion detection error: {e}")
                
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è Fallback detection error: {e}")
        
        return detections
    
    def detect_birds(self, frame: np.ndarray) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ô‡∏Å‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        all_detections = self.detect_objects(frame)
        birds = [det for det in all_detections if det['class'] == 'bird']
        return birds
    
    def detect_persons(self, frame: np.ndarray) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        all_detections = self.detect_objects(frame)
        persons = [det for det in all_detections if det['class'] == 'person']
        return persons
    
    def detect_animals(self, frame: np.ndarray) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        all_detections = self.detect_objects(frame)
        animal_classes = ['bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe']
        animals = [det for det in all_detections if det['class'] in animal_classes]
        return animals
    
    def detect_vehicles(self, frame: np.ndarray) -> List[Dict]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""
        all_detections = self.detect_objects(frame)
        vehicle_classes = ['car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'bicycle']
        vehicles = [det for det in all_detections if det['class'] in vehicle_classes]
        return vehicles
    
    def draw_detections(self, frame: np.ndarray, detections: List[Dict], show_confidence: bool = True) -> np.ndarray:
        """‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ö‡∏ô‡∏†‡∏≤‡∏û"""
        result_frame = frame.copy()
        
        for detection in detections:
            x, y, w, h = detection['bbox']
            class_name = detection['class']
            confidence = detection['confidence']
            class_id = detection.get('class_id', 0)
            
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏µ
            if class_id < len(self.colors):
                color = tuple(map(int, self.colors[class_id]))
            else:
                color = (0, 255, 0)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö
            cv2.rectangle(result_frame, (x, y), (x + w, y + h), color, 2)
            
            # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            if show_confidence:
                label = f"{class_name}: {confidence:.2f}"
            else:
                label = class_name
            
            # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(result_frame, (x, y - text_height - 10), (x + text_width, y), color, -1)
            
            # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            cv2.putText(result_frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á
            center = detection['center']
            cv2.circle(result_frame, center, 3, color, -1)
        
        return result_frame
    
    def get_detection_stats(self) -> Dict:
        """‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
        stats = self.detection_stats.copy()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        stats.update({
            'model_available': self.available,
            'classes_loaded': len(self.classes),
            'detection_rate': f"{stats['fps']:.1f} FPS" if stats['fps'] > 0 else "N/A",
            'uptime': time.time() - getattr(self, '_start_time', time.time())
        })
        
        return stats
    
    def get_model_info(self) -> Dict:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• model"""
        return self.model_info.copy()
    
    def reset_stats(self):
        """‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"""
        self.detection_stats = {
            'total_detections': 0,
            'birds_detected': 0,
            'persons_detected': 0,
            'animals_detected': 0,
            'vehicles_detected': 0,
            'processing_time': 0,
            'fps': 0,
            'last_detection_time': None
        }
        
        self.logger.info("üîÑ ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
    
    def set_confidence_threshold(self, threshold: float):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ confidence threshold"""
        if 0.0 <= threshold <= 1.0:
            self.confidence_threshold = threshold
            self.logger.info(f"üéØ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ confidence threshold = {threshold}")
        else:
            self.logger.warning(f"‚ö†Ô∏è confidence threshold ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 0.0-1.0")
    
    def set_nms_threshold(self, threshold: float):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ NMS threshold"""
        if 0.0 <= threshold <= 1.0:
            self.nms_threshold = threshold
            self.logger.info(f"üéØ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ NMS threshold = {threshold}")
        else:
            self.logger.warning(f"‚ö†Ô∏è NMS threshold ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 0.0-1.0")

def download_yolo_files():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå YOLO"""
    detector = OpenCVYOLODetector()
    return detector.available

def test_ultimate_ai_system():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö Ultimate AI System ‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"""
    print("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Ultimate AI Vision System...")
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô AI systems
    detector = OpenCVYOLODetector()
    
    # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI Helper Systems
    try:
        from ai_helper_system import get_ai_helper
        from ai_performance_booster import get_performance_booster
        
        ai_helper = get_ai_helper()
        performance_booster = get_performance_booster()
        
        # ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏∞‡∏ö‡∏ö AI
        ai_helper.register_ai_system("opencv_yolo_detector", detector)
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        performance_booster.optimize_ai_system(detector)
        
        print("‚úÖ AI Helper Systems ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
    except ImportError:
        print("‚ö†Ô∏è AI Helper Systems ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
        ai_helper = None
        performance_booster = None
    
    if not detector.available:
        print("‚ùå AI Detector ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        return False
    
    print("‚úÖ Ultimate AI System ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    print(f"üìä Model Info: {detector.get_model_info()}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á RTSP ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
    rtsp_urls = [
        "rtsp://ainok1:ainok123@192.168.1.100:554/stream1",
        "rtsp://admin:admin@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0",
        "rtsp://192.168.1.100:554/h264Preview_01_main",
        0  # ‡∏Å‡∏•‡πâ‡∏≠‡∏á USB
    ]
    
    cap = None
    connected = False
    used_url = None
    
    for rtsp_url in rtsp_urls:
        print(f"üìπ ‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: {rtsp_url}")
        cap = cv2.VideoCapture(rtsp_url)
        
        if cap.isOpened():
            ret, frame = cap.read()
            if ret and frame is not None:
                print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {rtsp_url}")
                connected = True
                used_url = rtsp_url
                break
            else:
                cap.release()
        else:
            if cap:
                cap.release()
    
    if not connected:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ")
        return False
    
    print("üé• ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Ultimate AI...")
    
    frame_count = 0
    detection_count = 0
    total_detections = 0
    start_time = time.time()
    
    # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    detection_types = {
        'birds': 0,
        'persons': 0, 
        'animals': 0,
        'vehicles': 0,
        'others': 0
    }
    
    try:
        while frame_count < 30:  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö 30 ‡πÄ‡∏ü‡∏£‡∏°
            ret, frame = cap.read()
            if not ret:
                continue
                
            frame_count += 1
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI Detection ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
            start_detect = time.time()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
            all_detections = detector.detect_objects(frame, conf_threshold=0.3)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
            birds = detector.detect_birds(frame)
            persons = detector.detect_persons(frame)
            animals = detector.detect_animals(frame)
            vehicles = detector.detect_vehicles(frame)
            
            detect_time = time.time() - start_detect
            
            if len(all_detections) > 0:
                detection_count += 1
                total_detections += len(all_detections)
                
                # ‡∏ô‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
                detection_types['birds'] += len(birds)
                detection_types['persons'] += len(persons)
                detection_types['animals'] += len(animals)
                detection_types['vehicles'] += len(vehicles)
                
                print(f"üéØ Frame {frame_count}: AI ‡∏û‡∏ö {len(all_detections)} objects ({detect_time*1000:.1f}ms)")
                
                for det in all_detections:
                    confidence = det['confidence']
                    class_name = det['class']
                    source = det['source']
                    print(f"   üìç {class_name}: {confidence:.2f} [{source}]")
                    
                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
                result_frame = detector.draw_detections(frame, all_detections)
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (optional)
                if frame_count % 10 == 0:
                    output_path = f"detection_result_frame_{frame_count}.jpg"
                    cv2.imwrite(output_path, result_frame)
                    print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û: {output_path}")
                    
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÉ‡∏ô AI Helper
            if ai_helper:
                metrics = ai_helper.collect_metrics("opencv_yolo_detector")
                if metrics and frame_count % 10 == 0:
                    print(f"üìä System Metrics - CPU: {metrics.cpu_usage:.1f}%, RAM: {metrics.memory_usage:.1f}%, FPS: {metrics.fps:.1f}")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            if frame_count % 5 == 0:
                elapsed = time.time() - start_time
                fps = frame_count / elapsed
                avg_detections = total_detections / max(detection_count, 1)
                print(f"üìä ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {frame_count}/30 ‡πÄ‡∏ü‡∏£‡∏° (FPS: {fps:.1f}, Avg Objects: {avg_detections:.1f})")
                
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {e}")
    finally:
        if cap:
            cap.release()
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    total_time = time.time() - start_time
    avg_fps = frame_count / total_time if total_time > 0 else 0
    detection_rate = (detection_count / frame_count) * 100 if frame_count > 0 else 0
    
    print(f"\nüìà ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Ultimate AI Vision System:")
    print(f"   üé¨ ‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {frame_count}")
    print(f"   üéØ ‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏µ‡πà AI ‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {detection_count}")
    print(f"   üìä ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö: {detection_rate:.1f}%")
    print(f"   üîç Objects ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_detections}")
    print(f"   ‚ö° FPS ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_fps:.1f}")
    print(f"   ‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_time:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    print(f"   üìπ ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {used_url}")
    
    # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    print(f"\nüéØ ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:")
    print(f"   üê¶ ‡∏ô‡∏Å: {detection_types['birds']}")
    print(f"   üë§ ‡∏Ñ‡∏ô: {detection_types['persons']}")
    print(f"   üêæ ‡∏™‡∏±‡∏ï‡∏ß‡πå: {detection_types['animals']}")
    print(f"   üöó ‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞: {detection_types['vehicles']}")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ detector
    stats = detector.get_detection_stats()
    print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ Detector:")
    print(f"   üîç ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {stats['total_detections']}")
    print(f"   üê¶ ‡∏ô‡∏Å‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {stats['birds_detected']}")
    print(f"   üë§ ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {stats['persons_detected']}")
    print(f"   üêæ ‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {stats['animals_detected']}")
    print(f"   üöó ‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {stats['vehicles_detected']}")
    print(f"   ‚ö° ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û: {stats['detection_rate']}")
    
    # ‡πÅ‡∏™‡∏î‡∏á AI Helper Dashboard
    if ai_helper:
        print(f"\nü§ñ AI Helper System Dashboard:")
        dashboard = ai_helper.get_system_dashboard()
        
        for system_id, data in dashboard['systems'].items():
            print(f"   {system_id}:")
            print(f"     ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: {data['status']}")
            print(f"     FPS: {data['fps']:.1f}")
            print(f"     ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {data['accuracy']:.2f}")
            print(f"     CPU: {data['cpu_usage']:.1f}%")
            print(f"     RAM: {data['memory_usage']:.1f}%")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
            recommendations = dashboard['recommendations'].get(system_id, [])
            if recommendations:
                print(f"     üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
                for rec in recommendations[:2]:
                    print(f"       - {rec['description']}")
    
    # ‡πÅ‡∏™‡∏î‡∏á Performance Report
    if performance_booster:
        print(f"\n‚ö° Performance Booster Report:")
        report = performance_booster.get_performance_report()
        metrics = report['performance_metrics']
        print(f"   FPS Improvement: +{metrics['fps_improvement']:.1f}%")
        print(f"   Memory Saved: +{metrics['memory_saved']:.1f}%")
        print(f"   Total Speedup: +{metrics['total_speedup']:.1f}%")
    
    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    success_score = 0
    if detection_count > 0:
        success_score += 40  # ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
    if avg_fps > 15:
        success_score += 30  # FPS ‡∏î‡∏µ
    if detection_rate > 50:
        success_score += 20  # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡∏µ
    if total_detections > 10:
        success_score += 10  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏î‡∏µ
    
    print(f"\nüèÜ ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {success_score}/100")
    
    if success_score >= 80:
        print("‚úÖ Ultimate AI Vision System ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°!")
        status = "EXCELLENT"
    elif success_score >= 60:
        print("‚úÖ Ultimate AI Vision System ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ!")
        status = "GOOD"
    elif success_score >= 40:
        print("‚ö†Ô∏è Ultimate AI Vision System ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á")
        status = "FAIR"
    else:
        print("‚ùå Ultimate AI Vision System ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á")
        status = "NEEDS_IMPROVEMENT"
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    if ai_helper:
        ai_helper.unregister_ai_system("opencv_yolo_detector")
    
    return status in ["EXCELLENT", "GOOD"]

# Test the ultimate system
if __name__ == "__main__":
    print("üöÄ Ultimate AI Vision System - ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
    print("="*60)
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    success = test_ultimate_ai_system()
    
    print("\n" + "="*60)
    if success:
        print("üéâ Ultimate AI Vision System ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Production!")
        print("üöÄ ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö")
    else:
        print("‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
        print("üîß ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á")
    
    print("="*60)
    print("‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å...")
    input()
